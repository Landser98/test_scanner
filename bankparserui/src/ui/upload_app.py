#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
New UI for uploading bank statements with automatic bank detection.
Handles multiple statements from different banks and saves to database.
"""

from __future__ import annotations

from pathlib import Path
import sys
from datetime import date
from typing import List, Dict, Any, Optional
import uuid
import base64

import pandas as pd
import streamlit as st
import requests

# --- ensure project root on sys.path ---
PROJECT_ROOT = Path(__file__).resolve().parents[2]
if str(PROJECT_ROOT) not in sys.path:
    sys.path.insert(0, str(PROJECT_ROOT))

from src.api.statement_processor import StatementProcessor
from src.core.analysis import get_last_full_12m_window, compute_ip_income_for_statement, combine_transactions
from src.db.database import DatabaseConnection, import_statement_to_db
from src.db.config import DB_CONFIG
from src.ui.ui_analysis_report_generator import get_ui_analysis_tables
from src.api.storage import get_storage
from src.api.taxpayer_api import TaxpayerAPIClient, TaxpayerType
from datetime import datetime

# ==================== –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã –¥–ª—è API –ø–æ–∏—Å–∫–∞ –Ω–∞–ª–æ–≥–æ–ø–ª–∞—Ç–µ–ª—å—â–∏–∫–∞ ====================
# –ù–∞—Å—Ç—Ä–æ–π—Ç–µ —ç—Ç–∏ –∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ API ¬´–ü–æ–∏—Å–∫ –ù–∞–ª–æ–≥–æ–ø–ª–∞—Ç–µ–ª—å—â–∏–∫–∞¬ª
# –ü–æ–ª—É—á–∏—Ç–µ —Ä–µ–∞–ª—å–Ω—ã–π URL –ø–æ—Ä—Ç–∞–ª–∞ —É –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–∞ –ö–ì–î –ú–§ –†–ö
# SECURITY: Use environment variables instead of hardcoded values
import os
TAXPAYER_API_PORTAL_HOST = os.environ.get(
    "TAXPAYER_API_PORTAL_HOST",
    ""
)
API_BASE_URL = os.environ.get("API_BASE_URL", "http://127.0.0.1:8000")


def check_api_health() -> tuple[bool, str]:
    """Check API availability for inter-service connectivity diagnostics."""
    try:
        response = requests.get(f"{API_BASE_URL.rstrip('/')}/livez", timeout=3)
        if response.status_code == 200:
            return True, "API –¥–æ—Å—Ç—É–ø–µ–Ω"
        return False, f"API –≤–µ—Ä–Ω—É–ª —Å—Ç–∞—Ç—É—Å {response.status_code}"
    except Exception as exc:
        return False, f"API –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {exc}"


def init_session_state() -> None:
    """Initialize session state variables"""
    if "upload_results" not in st.session_state:
        st.session_state.upload_results = []
    if "processed_statements" not in st.session_state:
        st.session_state.processed_statements = []
    if "projects_created" not in st.session_state:
        st.session_state.projects_created = []
    if "anchor_date" not in st.session_state:
        st.session_state.anchor_date = date.today()
    # Taxpayer search state
    if "taxpayer_search_results" not in st.session_state:
        st.session_state.taxpayer_search_results = []
    if "selected_project_id" not in st.session_state:
        st.session_state.selected_project_id = None


def format_bank_name(bank_key: str) -> str:
    """Format bank key to readable name"""
    bank_names = {
        "kaspi_gold": "Kaspi Gold",
        "kaspi_pay": "Kaspi Pay",
        "halyk_business": "Halyk Business",
        "halyk_individual": "Halyk Individual",
        "freedom_bank": "Freedom Bank",
        "forte_bank": "Forte Bank",
        "eurasian_bank": "Eurasian Bank",
        "bcc_bank": "BCC Bank",
        "alatau_city_bank": "Alatau City Bank",
    }
    return bank_names.get(bank_key, bank_key)


def _ensure_project_schema() -> None:
    db = DatabaseConnection(**DB_CONFIG)
    db.connect()
    try:
        db.ensure_project_schema()
    finally:
        db.disconnect()


def _create_project(name: str, created_by: str = "streamlit_8502") -> str:
    db = DatabaseConnection(**DB_CONFIG)
    db.connect()
    try:
        project_id = db.execute_insert(
            """
            INSERT INTO projects (name, status, created_by)
            VALUES (%s, 'draft', %s)
            RETURNING id
            """,
            (name.strip(), created_by),
        )
        return str(project_id)
    finally:
        db.disconnect()


def _list_projects() -> List[Dict[str, Any]]:
    db = DatabaseConnection(**DB_CONFIG)
    db.connect()
    try:
        rows = db.execute_query(
            """
            SELECT
                p.id,
                p.name,
                p.status,
                p.created_at,
                COUNT(ps.id) AS statements_count
            FROM projects p
            LEFT JOIN project_statements ps ON ps.project_id = p.id
            GROUP BY p.id, p.name, p.status, p.created_at
            ORDER BY p.created_at DESC
            """
        )
        return rows
    finally:
        db.disconnect()


def _count_project_statements(project_id: str) -> int:
    db = DatabaseConnection(**DB_CONFIG)
    db.connect()
    try:
        rows = db.execute_query(
            "SELECT COUNT(*) AS cnt FROM project_statements WHERE project_id = %s",
            (project_id,),
        )
        return int(rows[0]["cnt"]) if rows else 0
    finally:
        db.disconnect()


def _link_statement_to_project(
    project_id: str,
    statement_id: Optional[str],
    upload_order: int,
    source_filename: str,
    processing_status: str,
    processing_message: str,
) -> None:
    db = DatabaseConnection(**DB_CONFIG)
    db.connect()
    try:
        db.execute_insert(
            """
            INSERT INTO project_statements (
                project_id, statement_id, upload_order, source_filename, processing_status, processing_message
            )
            VALUES (%s, %s, %s, %s, %s, %s)
            RETURNING id
            """,
            (project_id, statement_id, upload_order, source_filename, processing_status, processing_message),
        )
    finally:
        db.disconnect()


def _update_project_status(project_id: str, status: str) -> None:
    db = DatabaseConnection(**DB_CONFIG)
    db.connect()
    try:
        db.execute_command(
            "UPDATE projects SET status = %s, updated_at = CURRENT_TIMESTAMP WHERE id = %s",
            (status, project_id),
        )
    finally:
        db.disconnect()


def _resolve_income_anchor_date(parsed_statement, fallback: Optional[date] = None) -> date:
    """
    Priority:
      1) statement_generation_date
      2) period_to
      3) fallback (UI selected date)
      4) today
    """
    for attr_name in ("statement_generation_date", "period_to"):
        raw_value = getattr(parsed_statement, attr_name, None)
        if raw_value is None:
            continue
        if isinstance(raw_value, datetime):
            return raw_value.date()
        if isinstance(raw_value, pd.Timestamp):
            return raw_value.date()
        if isinstance(raw_value, date):
            return raw_value
        parsed = pd.to_datetime(raw_value, errors="coerce")
        if pd.notna(parsed):
            return parsed.date()

    return fallback if fallback else date.today()


def _build_monthly_ip_income_df(enriched_df: Optional[pd.DataFrame]) -> Optional[pd.DataFrame]:
    """
    Build monthly IP income from rows marked as business income.
    Mirrors monthly table semantics from *_ip_income_monthly.csv.
    """
    if enriched_df is None or enriched_df.empty:
        return None
    if "txn_date" not in enriched_df.columns or "ip_credit_amount" not in enriched_df.columns:
        return None

    work_df = enriched_df.copy()
    work_df["txn_date"] = pd.to_datetime(work_df["txn_date"], errors="coerce")
    work_df = work_df[work_df["txn_date"].notna()]

    if "ip_is_business_income" in work_df.columns:
        work_df = work_df[work_df["ip_is_business_income"].fillna(False).astype(bool)].copy()
    else:
        work_df = work_df[work_df["ip_credit_amount"].fillna(0.0) > 0].copy()

    if work_df.empty:
        return pd.DataFrame(columns=["month", "business_income"])

    work_df["month"] = work_df["txn_date"].dt.to_period("M").astype(str)
    monthly_summary = (
        work_df.groupby("month", as_index=False)
        .agg(
            business_income=("ip_credit_amount", "sum"),
            transaction_count=("ip_credit_amount", "count"),
        )
    )
    return monthly_summary


def set_transaction_dates_to_today(statement, target_date: Optional[date] = None) -> None:
    """
    –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –≤—Å–µ –¥–∞—Ç—ã —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π –Ω–∞ —É–∫–∞–∑–∞–Ω–Ω—É—é –¥–∞—Ç—É (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é —Å–µ–≥–æ–¥–Ω—è) –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è.
    –≠—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏—è–º –ø–æ–ø–∞–¥–∞—Ç—å –≤ 12-–º–µ—Å—è—á–Ω–æ–µ –æ–∫–Ω–æ.
    """
    if not hasattr(statement, "tx_df") or statement.tx_df is None or statement.tx_df.empty:
        return
    
    # –†–∞–±–æ—Ç–∞–µ–º –Ω–∞–ø—Ä—è–º—É—é —Å DataFrame, —á—Ç–æ–±—ã –∏–∑–º–µ–Ω–µ–Ω–∏—è —Å–æ—Ö—Ä–∞–Ω–∏–ª–∏—Å—å
    df = statement.tx_df
    target = target_date if target_date else date.today()
    target_ts = pd.Timestamp(target)
    
    # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –¥–∞—Ç—ã –¥–ª—è –≤—Å–µ—Ö —Å—Ç—Ä–æ–∫
    if "txn_date" not in df.columns:
        # –ï—Å–ª–∏ –∫–æ–ª–æ–Ω–∫–∏ txn_date –Ω–µ—Ç, —Å–æ–∑–¥–∞–µ–º –µ—ë
        df["txn_date"] = target_ts
    else:
        # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –≤—Å–µ –¥–∞—Ç—ã –Ω–∞ —Ü–µ–ª–µ–≤—É—é –¥–∞—Ç—É –¥–ª—è –≤—Å–µ—Ö —Å—Ç—Ä–æ–∫
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º .loc –¥–ª—è –≥–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤—Å–µ—Ö –∑–Ω–∞—á–µ–Ω–∏–π
        df.loc[:, "txn_date"] = target_ts
    
    # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ —Ç–∏–ø –¥–∞–Ω–Ω—ã—Ö –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π
    if not pd.api.types.is_datetime64_any_dtype(df["txn_date"]):
        df["txn_date"] = pd.to_datetime(df["txn_date"], errors="coerce")
    
    # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ –∏–∑–º–µ–Ω–µ–Ω–∏—è –ø—Ä–∏–º–µ–Ω–µ–Ω—ã
    statement.tx_df = df


def process_statements_like_upload_initial(
    uploaded_files: List,
    processor: StatementProcessor,
    anchor_date: Optional[date] = None
) -> Dict[str, Any]:
    """
    Process statements similar to upload_initial API endpoint.
    Groups statements by IIN and creates projects.
    """
    storage = get_storage()
    all_results = []
    projects_created = []
    
    # Step 1: Parse all statements
    statements_data = []  # (statement_id, pdf_bytes, filename, parse_result)
    parsed_statements_by_iin = {}  # {iin: [parsed_statements]}
    
    for uploaded_file in uploaded_files:
        statement_id = str(uuid.uuid4())
        pdf_bytes = uploaded_file.read()
        base64_data = base64.b64encode(pdf_bytes).decode('utf-8')
        extension = ".pdf" if uploaded_file.name.lower().endswith('.pdf') else ""
        
        # Parse statement
        parse_result = processor.parse_statement_base64(
            statement_id=statement_id,
            statement_name=uploaded_file.name,
            extension=extension,
            base64_data=base64_data,
            expected_iin=None  # No IIN validation
        )
        
        statements_data.append((statement_id, pdf_bytes, uploaded_file.name, parse_result))
        
        # Extract IIN from parsed statement
        parsed_statement = parse_result.get("parsed_statement")
        if parsed_statement:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–µ–∞–ª—å–Ω—ã–µ –¥–∞—Ç—ã —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π –∏–∑ –≤—ã–ø–∏—Å–æ–∫
            pass
            
            iin = getattr(parsed_statement, "iin_bin", None)
            if iin:
                iin = iin.strip()
                if iin not in parsed_statements_by_iin:
                    parsed_statements_by_iin[iin] = []
                parsed_statements_by_iin[iin].append({
                    "statement_id": statement_id,
                    "parsed_statement": parsed_statement,
                    "parse_result": parse_result,
                    "pdf_bytes": pdf_bytes,
                    "filename": uploaded_file.name
                })
    
    # Step 2: Process each IIN group (like upload_initial)
    for iin, statements_group in parsed_statements_by_iin.items():
        statements_resp = []
        parsed_statements = []
        statement_files_data = []
        has_data_mismatch = False
        has_failure = False
        
        # Process each statement in the group
        for stmt_data in statements_group:
            parse_result = stmt_data["parse_result"]
            parsed_statement = stmt_data["parsed_statement"]
            statement_id = stmt_data["statement_id"]
            pdf_bytes = stmt_data["pdf_bytes"]
            filename = stmt_data["filename"]
            
            # Track status
            status = parse_result.get("status")
            if status == processor.STATUS_DATA_MISMATCH:
                has_data_mismatch = True
            elif status == processor.STATUS_FAILURE or status == processor.STATUS_SCANNED_COPY:
                has_failure = True
            
            # Store file data
            ext = ".pdf" if filename.lower().endswith('.pdf') else ""
            if ext and not filename.endswith(ext):
                filename = f"{filename}{ext}"
            statement_files_data.append((statement_id, pdf_bytes, filename))
            
            # Add to response
            statements_resp.append({
                'id': statement_id,
                'name': filename,
                'extension': ext,
                'status': status,
                'message': parse_result.get("message", "")
            })
            
            # Process and save to DB if successful
            if status == processor.STATUS_SUCCESS:
                try:
                    # Calculate income in the same way as batch parsers:
                    # anchor by statement date, fallback to UI-selected date.
                    calc_date = _resolve_income_anchor_date(parsed_statement, fallback=anchor_date)
                    window_start, window_end = get_last_full_12m_window(calc_date)
                    
                    enriched_df, income_summary = compute_ip_income_for_statement(
                        parsed_statement,
                        window_start,
                        window_end
                    )
                    
                    # Prepare monthly income DataFrame
                    monthly_income_df = _build_monthly_ip_income_df(enriched_df)
                    
                    # Save to database
                    bank_name = format_bank_name(getattr(parsed_statement, "bank", "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"))
                    statement_data = {
                        'header_df': getattr(parsed_statement, 'header_df', None),
                        'tx_df': getattr(parsed_statement, 'tx_df', None),
                        'footer_df': getattr(parsed_statement, 'footer_df', None),
                        'meta_df': getattr(parsed_statement, 'meta_df', None),
                        'tx_ip_df': enriched_df,
                        'monthly_income_df': monthly_income_df,
                        'income_summary': income_summary if income_summary else {},
                        'client_iin': iin,  # –ò–ò–ù –∏–∑–≤–ª–µ–∫–∞–µ—Ç—Å—è –∏–∑ –≤—ã–ø–∏—Å–∫–∏
                        'client_name': getattr(parsed_statement, 'account_holder_name', None),
                        'account_number': getattr(parsed_statement, 'account_number', None),
                        'pdf_name': filename,
                    }
                    
                    db = DatabaseConnection(**DB_CONFIG)
                    db.connect()
                    db_statement_id = import_statement_to_db(db, statement_data, bank_name)
                    db.disconnect()
                    
                    # Store for analytics
                    parsed_statement.enriched_df = enriched_df
                    parsed_statement.monthly_income_df = monthly_income_df
                    parsed_statement.income_summary = income_summary
                    parsed_statements.append(parsed_statement)
                    
                    all_results.append({
                        "statement_id": statement_id,
                        "statement_name": filename,
                        "status": "success",
                        "message": f"–£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ –ë–î (ID: {db_statement_id})",
                        "bank": getattr(parsed_statement, "bank", "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"),
                        "iin": iin,
                        "income_summary": income_summary,
                        "db_statement_id": db_statement_id,
                        "parsed_statement": parsed_statement
                    })
                    
                except Exception as e:
                    all_results.append({
                        "statement_id": statement_id,
                        "statement_name": filename,
                        "status": "error",
                        "message": f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ –ë–î: {str(e)}",
                        "bank": getattr(parsed_statement, "bank", "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"),
                        "iin": iin,
                        "error": str(e),
                        "parsed_statement": None
                    })
            else:
                # Failed parsing
                all_results.append({
                    "statement_id": statement_id,
                    "statement_name": filename,
                    "status": "error" if status == processor.STATUS_FAILURE else "warning",
                    "message": parse_result.get("message", ""),
                    "bank": getattr(parsed_statement, "bank", "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ") if parsed_statement else "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ",
                    "iin": iin if parsed_statement else None,
                    "error": parse_result.get("error"),
                    "parsed_statement": None
                })
        
        # Calculate analytics for this IIN group
        analytics = {}
        if parsed_statements:
            analytics = processor.calculate_analytics(parsed_statements)
        
        # Determine project status
        if has_data_mismatch:
            project_status = 2
            response_message = "–†–∞—Å—Ö–æ–∂–¥–µ–Ω–∏–µ —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–æ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"
        elif has_failure:
            project_status = 1
            response_message = "–ü—Ä–æ–≤–∞–ª"
        else:
            project_status = 0
            response_message = "–£—Å–ø–µ—Ö"
        
        # Create project (like upload_initial)
        project = storage.create_project(
            iin=iin,
            statements=statements_resp,
            analytics=analytics,
            status=project_status
        )
        
        # Save statement files
        for statement_id, pdf_bytes, filename in statement_files_data:
            storage.save_statement_file(
                project_id=project.project_id,
                statement_id=statement_id,
                file_data=pdf_bytes,
                filename=filename
            )
        
        projects_created.append({
            "project_id": project.project_id,
            "iin": iin,
            "status": project_status,
            "message": response_message,
            "create_date": project.create_date,
            "analytics": analytics,
            "statements_count": len(statements_resp)
        })
    
    # Process statements without IIN (create separate project or mark as error)
    statements_without_iin = []
    for statement_id, pdf_bytes, filename, parse_result in statements_data:
        parsed_statement = parse_result.get("parsed_statement")
        if not parsed_statement:
            iin = None
        else:
            iin = getattr(parsed_statement, "iin_bin", None)
            if iin:
                iin = iin.strip()
        
        # If statement doesn't have IIN or wasn't processed above
        if not iin or iin not in parsed_statements_by_iin:
            statements_without_iin.append({
                "statement_id": statement_id,
                "pdf_bytes": pdf_bytes,
                "filename": filename,
                "parse_result": parse_result,
                "parsed_statement": parsed_statement
            })
    
    # Create project for statements without IIN (use "UNKNOWN" as IIN)
    if statements_without_iin:
        statements_resp = []
        parsed_statements = []
        statement_files_data = []
        has_failure = False
        
        for stmt_data in statements_without_iin:
            parse_result = stmt_data["parse_result"]
            parsed_statement = stmt_data["parsed_statement"]
            statement_id = stmt_data["statement_id"]
            pdf_bytes = stmt_data["pdf_bytes"]
            filename = stmt_data["filename"]
            
            status = parse_result.get("status")
            if status == processor.STATUS_FAILURE or status == processor.STATUS_SCANNED_COPY:
                has_failure = True
            
            ext = ".pdf" if filename.lower().endswith('.pdf') else ""
            if ext and not filename.endswith(ext):
                filename = f"{filename}{ext}"
            statement_files_data.append((statement_id, pdf_bytes, filename))
            
            statements_resp.append({
                'id': statement_id,
                'name': filename,
                'extension': ext,
                'status': status,
                'message': parse_result.get("message", "–ò–ò–ù –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –≤—ã–ø–∏—Å–∫–µ")
            })
            
            if parsed_statement and status == processor.STATUS_SUCCESS:
                parsed_statements.append(parsed_statement)
            
            all_results.append({
                "statement_id": statement_id,
                "statement_name": filename,
                "status": "error" if status == processor.STATUS_FAILURE else "warning",
                "message": parse_result.get("message", "–ò–ò–ù –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –≤—ã–ø–∏—Å–∫–µ"),
                "bank": getattr(parsed_statement, "bank", "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ") if parsed_statement else "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ",
                "iin": "–ù–µ –Ω–∞–π–¥–µ–Ω",
                "error": parse_result.get("error") or "–ò–ò–ù –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –≤—ã–ø–∏—Å–∫–µ. –ü—Ä–æ–≤–µ—Ä–∫–∞ —á–µ—Ä–µ–∑ API –°–æ–ª–∏–∫ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞.",
                "parsed_statement": None
            })
        
        # Create project with "UNKNOWN" IIN
        if statements_resp:
            project_status = 1 if has_failure else 0
            response_message = "–ò–ò–ù –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –≤—ã–ø–∏—Å–∫–∞—Ö" if has_failure else "–£—Å–ø–µ—Ö (–ò–ò–ù –Ω–µ –Ω–∞–π–¥–µ–Ω)"
            
            project = storage.create_project(
                iin="UNKNOWN",
                statements=statements_resp,
                analytics={},
                status=project_status
            )
            
            # Save files
            for statement_id, pdf_bytes, filename in statement_files_data:
                storage.save_statement_file(
                    project_id=project.project_id,
                    statement_id=statement_id,
                    file_data=pdf_bytes,
                    filename=filename
                )
            
            projects_created.append({
                "project_id": project.project_id,
                "iin": "UNKNOWN",
                "status": project_status,
                "message": response_message,
                "create_date": project.create_date,
                "analytics": {},
                "statements_count": len(statements_resp)
            })
    
    return {
        "results": all_results,
        "projects": projects_created
    }


def process_statements_for_project(
    uploaded_files: List,
    project_id: str,
    processor: StatementProcessor,
    anchor_date: Optional[date] = None
) -> Dict[str, Any]:
    """
    Process uploaded statements and attach each result to a selected DB project.
    Limits must be validated before call.
    """
    results: List[Dict[str, Any]] = []
    existing_count = _count_project_statements(project_id)
    processed = skipped = failed = 0

    _update_project_status(project_id, "processing")

    for idx, uploaded_file in enumerate(uploaded_files, start=1):
        statement_id = str(uuid.uuid4())
        filename = uploaded_file.name
        pdf_bytes = uploaded_file.read()
        base64_data = base64.b64encode(pdf_bytes).decode("utf-8")

        parse_result = processor.parse_statement_base64(
            statement_id=statement_id,
            statement_name=filename,
            extension=".pdf",
            base64_data=base64_data,
            expected_iin=None
        )

        parsed_statement = parse_result.get("parsed_statement")
        status_code = parse_result.get("status")
        upload_order = existing_count + idx

        if not parsed_statement or status_code != processor.STATUS_SUCCESS:
            message = parse_result.get("message", "–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞")
            _link_statement_to_project(
                project_id=project_id,
                statement_id=None,
                upload_order=upload_order,
                source_filename=filename,
                processing_status="error",
                processing_message=message,
            )
            failed += 1
            results.append({
                "statement_id": statement_id,
                "statement_name": filename,
                "status": "error",
                "message": message,
                "bank": getattr(parsed_statement, "bank", "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ") if parsed_statement else "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ",
                "iin": getattr(parsed_statement, "iin_bin", None) if parsed_statement else None,
                "parsed_statement": parsed_statement,
            })
            continue

        iin = (getattr(parsed_statement, "iin_bin", None) or "").strip()
        if not iin:
            msg = "–ü—Ä–æ–ø—É—â–µ–Ω–æ: –Ω–µ—Ç –ò–ò–ù/–ë–ò–ù/–ò–ù–ù –¥–∞–Ω–Ω—ã—Ö –¥–ª—è IP —Ä–∞—Å—á–µ—Ç–∞"
            _link_statement_to_project(
                project_id=project_id,
                statement_id=None,
                upload_order=upload_order,
                source_filename=filename,
                processing_status="skipped",
                processing_message=msg,
            )
            skipped += 1
            results.append({
                "statement_id": statement_id,
                "statement_name": filename,
                "status": "warning",
                "message": msg,
                "bank": getattr(parsed_statement, "bank", "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"),
                "iin": None,
                "parsed_statement": parsed_statement,
            })
            continue

        try:
            calc_date = _resolve_income_anchor_date(parsed_statement, fallback=anchor_date)
            window_start, window_end = get_last_full_12m_window(calc_date)
            enriched_df, income_summary = compute_ip_income_for_statement(
                parsed_statement,
                window_start,
                window_end
            )
            monthly_income_df = _build_monthly_ip_income_df(enriched_df)

            statement_data = {
                'header_df': getattr(parsed_statement, 'header_df', None),
                'tx_df': getattr(parsed_statement, 'tx_df', None),
                'footer_df': getattr(parsed_statement, 'footer_df', None),
                'meta_df': getattr(parsed_statement, 'meta_df', None),
                'tx_ip_df': enriched_df,
                'monthly_income_df': monthly_income_df,
                'income_summary': income_summary if income_summary else {},
                'client_iin': iin,
                'client_name': getattr(parsed_statement, 'account_holder_name', None),
                'account_number': getattr(parsed_statement, 'account_number', None),
                'pdf_name': filename,
            }

            bank_name = format_bank_name(getattr(parsed_statement, "bank", "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"))
            db = DatabaseConnection(**DB_CONFIG)
            db.connect()
            db_statement_id = import_statement_to_db(db, statement_data, bank_name)
            db.disconnect()

            _link_statement_to_project(
                project_id=project_id,
                statement_id=str(db_statement_id),
                upload_order=upload_order,
                source_filename=filename,
                processing_status="success",
                processing_message="–£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ",
            )

            parsed_statement.enriched_df = enriched_df
            parsed_statement.monthly_income_df = monthly_income_df
            parsed_statement.income_summary = income_summary
            processed += 1
            results.append({
                "statement_id": statement_id,
                "statement_name": filename,
                "status": "success",
                "message": f"–£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∏ –ø—Ä–∏–≤—è–∑–∞–Ω–æ –∫ –ø—Ä–æ–µ–∫—Ç—É {project_id}",
                "bank": getattr(parsed_statement, "bank", "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"),
                "iin": iin,
                "income_summary": income_summary,
                "db_statement_id": db_statement_id,
                "parsed_statement": parsed_statement,
            })
        except Exception as e:
            _link_statement_to_project(
                project_id=project_id,
                statement_id=None,
                upload_order=upload_order,
                source_filename=filename,
                processing_status="error",
                processing_message=f"–û—à–∏–±–∫–∞ –ë–î: {e}",
            )
            failed += 1
            results.append({
                "statement_id": statement_id,
                "statement_name": filename,
                "status": "error",
                "message": f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ –ë–î: {e}",
                "bank": getattr(parsed_statement, "bank", "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"),
                "iin": iin,
                "parsed_statement": parsed_statement,
            })

    if failed > 0 and processed == 0:
        _update_project_status(project_id, "failed")
    elif failed > 0 or skipped > 0:
        _update_project_status(project_id, "completed_with_warnings")
    else:
        _update_project_status(project_id, "completed")

    return {
        "results": results,
        "processed": processed,
        "skipped": skipped,
        "failed": failed,
    }


def process_and_save_statement(
    statement_id: str,
    statement_name: str,
    pdf_bytes: bytes,
    processor: StatementProcessor,
    anchor_date: Optional[date] = None
) -> Dict[str, Any]:
    """
    Process statement and save to database.
    Returns result dict with status, message, and data.
    """
    result = {
        "statement_id": statement_id,
        "statement_name": statement_name,
        "status": "pending",
        "message": "",
        "bank": None,
        "iin": None,
        "income_summary": None,
        "error": None,
        "db_statement_id": None,
    }
    
    try:
        # Encode to base64 for processor
        base64_data = base64.b64encode(pdf_bytes).decode('utf-8')
        extension = ".pdf" if statement_name.lower().endswith('.pdf') else ""
        
        # Parse statement (automatic bank detection)
        parse_result = processor.parse_statement_base64(
            statement_id=statement_id,
            statement_name=statement_name,
            extension=extension,
            base64_data=base64_data,
            expected_iin=None  # No IIN validation for now
        )
        
        result["status_code"] = parse_result.get("status")
        result["message"] = parse_result.get("message", "")
        result["error"] = parse_result.get("error")
        
        parsed_statement = parse_result.get("parsed_statement")
        
        if not parsed_statement:
            result["status"] = "error"
            result["message"] = f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞: {result.get('error', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞')}"
            return result
        
        # Extract bank and IIN
        result["bank"] = getattr(parsed_statement, "bank", "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ")
        result["iin"] = getattr(parsed_statement, "iin_bin", None)
        
        # Check if parsing was successful
        if parse_result.get("status") != processor.STATUS_SUCCESS:
            result["status"] = "warning"
            if parse_result.get("status") == processor.STATUS_SCANNED_COPY:
                result["message"] = "–ó–∞–≥—Ä—É–∂–µ–Ω—ã —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∫–æ–ø–∏–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞"
            elif parse_result.get("status") == processor.STATUS_DATA_MISMATCH:
                result["message"] = "–†–∞—Å—Ö–æ–∂–¥–µ–Ω–∏–µ —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–æ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"
            else:
                result["status"] = "error"
            return result
        
        # Calculate income in the same way as batch parsers:
        # anchor by statement date, fallback to UI-selected date.
        calc_date = _resolve_income_anchor_date(parsed_statement, fallback=anchor_date)
        window_start, window_end = get_last_full_12m_window(calc_date)
        
        enriched_df = None
        income_summary = None
        monthly_income_df = None
        
        try:
            enriched_df, income_summary = compute_ip_income_for_statement(
                parsed_statement,
                window_start,
                window_end
            )
            result["income_summary"] = income_summary
            
            # Extract monthly income from enriched_df
            monthly_income_df = _build_monthly_ip_income_df(enriched_df)
        except Exception as e:
            result["error"] = f"–û—à–∏–±–∫–∞ —Ä–∞—Å—á–µ—Ç–∞ –¥–æ—Ö–æ–¥–∞: {str(e)}"
            result["status"] = "warning"
        
        # Prepare data for database
        try:
            # Get bank name for database
            bank_name = format_bank_name(result["bank"])
            
            # Prepare statement data
            statement_data = {
                'header_df': getattr(parsed_statement, 'header_df', None),
                'tx_df': getattr(parsed_statement, 'tx_df', None),
                'footer_df': getattr(parsed_statement, 'footer_df', None),
                'meta_df': getattr(parsed_statement, 'meta_df', None),
                'tx_ip_df': enriched_df,
                'monthly_income_df': monthly_income_df,
                'income_summary': income_summary if income_summary else {},
                'client_iin': result["iin"],
                'client_name': getattr(parsed_statement, 'account_holder_name', None),
                'account_number': getattr(parsed_statement, 'account_number', None),
                'pdf_name': statement_name,
            }
            
            # Save to database
            db = DatabaseConnection(**DB_CONFIG)
            db.connect()
            
            db_statement_id = import_statement_to_db(db, statement_data, bank_name)
            db.disconnect()
            
            result["db_statement_id"] = db_statement_id
            result["status"] = "success"
            result["message"] = f"–£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ –ë–î (ID: {db_statement_id})"
            
            # Store processed statement for later use
            parsed_statement.enriched_df = enriched_df if 'enriched_df' in locals() else None
            parsed_statement.monthly_income_df = monthly_income_df
            parsed_statement.income_summary = income_summary
            result["parsed_statement"] = parsed_statement
            
        except Exception as e:
            result["error"] = f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ –ë–î: {str(e)}"
            result["status"] = "error"
            result["message"] = f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ –ë–î: {str(e)}"
    
    except Exception as e:
        result["status"] = "error"
        result["error"] = str(e)
        result["message"] = f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {str(e)}"
    
    return result


def display_results(results: List[Dict[str, Any]]):
    """Display processing results"""
    if not results:
        return
    
    st.header("üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—Ä–∞–±–æ—Ç–∫–∏")
    
    # Summary statistics
    success_count = sum(1 for r in results if r.get("status") == "success")
    error_count = sum(1 for r in results if r.get("status") == "error")
    warning_count = sum(1 for r in results if r.get("status") == "warning")
    
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("–í—Å–µ–≥–æ", len(results))
    with col2:
        st.metric("–£—Å–ø–µ—à–Ω–æ", success_count, delta=f"+{success_count}")
    with col3:
        st.metric("–û—à–∏–±–∫–∏", error_count, delta=f"-{error_count}" if error_count > 0 else None)
    with col4:
        st.metric("–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è", warning_count)
    
    # Detailed results table
    st.subheader("–î–µ—Ç–∞–ª–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏")
    
    results_data = []
    for r in results:
        income = r.get("income_summary", {})
        total_income = income.get("total_income_adjusted", 0) if income else 0
        
        status_ru = {
            "success": "–£—Å–ø–µ—à–Ω–æ",
            "error": "–û—à–∏–±–∫–∞",
            "warning": "–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ",
            "pending": "–í –æ–±—Ä–∞–±–æ—Ç–∫–µ"
        }.get(r.get("status", "unknown"), r.get("status", "–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"))
        
        results_data.append({
            "–§–∞–π–ª": r.get("statement_name", "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"),
            "–ë–∞–Ω–∫": format_bank_name(r.get("bank", "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ")),
            "–ò–ò–ù": r.get("iin", "–ù–µ –Ω–∞–π–¥–µ–Ω"),
            "–°—Ç–∞—Ç—É—Å": status_ru,
            "–î–æ—Ö–æ–¥ (12 –º–µ—Å)": f"{total_income:,.2f} ‚Ç∏" if total_income > 0 else "–ù–µ —Ä–∞—Å—Å—á–∏—Ç–∞–Ω",
            "–°–æ–æ–±—â–µ–Ω–∏–µ": r.get("message", ""),
            "ID –≤ –ë–î": r.get("db_statement_id", "–ù–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ"),
        })
    
    if results_data:
        df_results = pd.DataFrame(results_data)
        st.dataframe(df_results, use_container_width=True, hide_index=True)
    
    # Errors and warnings
    errors = [r for r in results if r.get("status") == "error"]
    warnings = [r for r in results if r.get("status") == "warning"]
    
    if errors:
        st.error("‚ùå –û—à–∏–±–∫–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏:")
        for err in errors:
            st.error(f"**{err.get('statement_name')}**: {err.get('message')}")
            if err.get("error"):
                with st.expander("–î–µ—Ç–∞–ª–∏ –æ—à–∏–±–∫–∏"):
                    st.code(err.get("error"))
    
    if warnings:
        st.warning("‚ö†Ô∏è –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è:")
        for warn in warnings:
            st.warning(f"**{warn.get('statement_name')}**: {warn.get('message')}")
    
    # Income summaries
    successful = [r for r in results if r.get("status") == "success" and r.get("income_summary")]
    if successful:
        st.subheader("üí∞ –†–∞—Å—á–µ—Ç –¥–æ—Ö–æ–¥–∞")
        
        total_income_all = 0
        for r in successful:
            income = r.get("income_summary", {})
            total_income = income.get("total_income_adjusted", 0) if income else 0
            total_income_all += total_income
            
            st.info(f"**{r.get('statement_name')}** ({format_bank_name(r.get('bank'))}): "
                   f"–î–æ—Ö–æ–¥ –∑–∞ 12 –º–µ—Å—è—Ü–µ–≤: **{total_income:,.2f} ‚Ç∏**")
        
        if len(successful) > 1:
            st.success(f"**–û–±—â–∏–π –¥–æ—Ö–æ–¥ –ø–æ –≤—Å–µ–º –≤—ã–ø–∏—Å–∫–∞–º: {total_income_all:,.2f} ‚Ç∏**")


def display_admin_tables(processed_statements: List[Any]):
    """Display admin tables from processed statements"""
    if not processed_statements:
        return
    
    st.header("üìã –ê–¥–º–∏–Ω–∫–∞ - –ê–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–µ —Ç–∞–±–ª–∏—Ü—ã")
    
    # –ß–µ–∫–±–æ–∫—Å –¥–ª—è –≤—ã–±–æ—Ä–∞ - —É—á–∏—Ç—ã–≤–∞—Ç—å –¥–∞—Ç—ã –∏–ª–∏ –Ω–µ—Ç
    if "filter_by_date" not in st.session_state:
        st.session_state.filter_by_date = False
    
    filter_by_date = st.checkbox(
        "–§–∏–ª—å—Ç—Ä–æ–≤–∞—Ç—å —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏ –ø–æ –¥–∞—Ç–∞–º",
        value=st.session_state.filter_by_date,
        help="–ï—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–æ, —É—á–∏—Ç—ã–≤–∞—é—Ç—Å—è —Ç–æ–ª—å–∫–æ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏ –≤ —É–∫–∞–∑–∞–Ω–Ω–æ–º –¥–∏–∞–ø–∞–∑–æ–Ω–µ –¥–∞—Ç. –ï—Å–ª–∏ –≤—ã–∫–ª—é—á–µ–Ω–æ, —É—á–∏—Ç—ã–≤–∞—é—Ç—Å—è –≤—Å–µ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏."
    )
    st.session_state.filter_by_date = filter_by_date
    
    # Combine transactions from all statements
    anchor_date = st.session_state.anchor_date
    _, window_end_calc = get_last_full_12m_window(anchor_date)
    
    all_statements = [r.get("parsed_statement") for r in processed_statements 
                     if r.get("parsed_statement") and hasattr(r.get("parsed_statement"), "tx_df")]
    
    if not all_statements:
        st.info("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è")
        return
    
    total_tx_before = 0
    for stmt in all_statements:
        if stmt and hasattr(stmt, "tx_df") and not stmt.tx_df.empty:
            total_tx_before += len(stmt.tx_df)
    
    # –û—Ç–ª–∞–¥–æ—á–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
    if total_tx_before == 0:
        st.warning(f"‚ö†Ô∏è –í—Å–µ–≥–æ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π –≤ –≤—ã–ø–∏—Å–∫–∞—Ö: {total_tx_before}")
        st.info("–ù–µ—Ç —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
        return
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –æ–∫–Ω–æ –¥–∞—Ç (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ filter_by_date = True)
    # –î–ª—è —Ç–µ—Å—Ç–∞: –≥–æ–¥ –Ω–∞—á–∏–Ω–∞—è —Å anchor_date
    window_start, window_end = get_last_full_12m_window(anchor_date)
    
    if filter_by_date:
        st.info(f"üìÖ –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –¥–∞—Ç–∞–º –≤–∫–ª—é—á–µ–Ω–∞. –û–∫–Ω–æ: {window_start} ‚Üí {window_end}")
    else:
        st.info("üìÖ –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –¥–∞—Ç–∞–º –≤—ã–∫–ª—é—á–µ–Ω–∞. –£—á–∏—Ç—ã–≤–∞—é—Ç—Å—è –≤—Å–µ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏.")
    
    # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏ (—Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π –∏–ª–∏ –±–µ–∑)
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º **kwargs –¥–ª—è –ø–µ—Ä–µ–¥–∞—á–∏ filter_by_date, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –æ—à–∏–±–æ–∫, –µ—Å–ª–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è
    try:
        tx_12m = combine_transactions(all_statements, window_start, window_end, filter_by_date=filter_by_date)
    except TypeError as e:
        # –ï—Å–ª–∏ —Ñ—É–Ω–∫—Ü–∏—è –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç filter_by_date, –≤—ã–∑—ã–≤–∞–µ–º –±–µ–∑ –Ω–µ–≥–æ (–¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)
        if "filter_by_date" in str(e):
            tx_12m = combine_transactions(all_statements, window_start, window_end)
            # –í—Ä—É—á–Ω—É—é —Ñ–∏–ª—å—Ç—Ä—É–µ–º, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            if filter_by_date:
                if not tx_12m.empty and "txn_date" in tx_12m.columns:
                    mask = (tx_12m["txn_date"] >= pd.Timestamp(window_start)) & (tx_12m["txn_date"] <= pd.Timestamp(window_end))
                    tx_12m = tx_12m.loc[mask].copy()
        else:
            raise
    
    if tx_12m.empty:
        st.warning(f"‚ö†Ô∏è –í—Å–µ–≥–æ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π –≤ –≤—ã–ø–∏—Å–∫–∞—Ö: {total_tx_before}")
        if filter_by_date:
            st.warning(f"‚ö†Ô∏è –û–∫–Ω–æ –∞–Ω–∞–ª–∏–∑–∞: {window_start} ‚Üí {window_end}")
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä—ã –¥–∞—Ç –∏–∑ –≤—ã–ø–∏—Å–æ–∫ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
        for stmt in all_statements:
            if stmt and hasattr(stmt, "tx_df") and not stmt.tx_df.empty:
                if "txn_date" in stmt.tx_df.columns:
                    sample_dates = stmt.tx_df["txn_date"].head(3).tolist()
                    unique_dates = stmt.tx_df["txn_date"].unique()[:5]
                    st.write(f"**{stmt.pdf_name}**: –ü—Ä–∏–º–µ—Ä—ã –¥–∞—Ç: {sample_dates}, –£–Ω–∏–∫–∞–ª—å–Ω—ã–µ: {[str(d) for d in unique_dates]}")
        st.info("–ù–µ—Ç —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
        return
    
    # Prepare data for analysis
    df_analysis = tx_12m.copy()
    
    # Clean amounts
    def clean_amt_val(v):
        if pd.isna(v) or v == '':
            return 0.0
        if isinstance(v, (int, float)):
            return float(v)
        s = str(v).replace(',', '').replace(' ', '').replace('\xa0', '').replace('\u00A0', '').strip()
        try:
            return float(s)
        except:
            return 0.0
    
    # Determine amount column
    if '–î–µ–±–µ—Ç' in df_analysis.columns and '–ö—Ä–µ–¥–∏—Ç' in df_analysis.columns:
        d_clean = df_analysis['–î–µ–±–µ—Ç'].apply(clean_amt_val)
        k_clean = df_analysis['–ö—Ä–µ–¥–∏—Ç'].apply(clean_amt_val)
        df_analysis['amount'] = k_clean - d_clean
    elif 'amount' not in df_analysis.columns:
        amt_col = next((c for c in ['–°—É–º–º–∞ –æ–ø–µ—Ä–∞—Ü–∏–∏', '–°—É–º–º–∞', '–†–∞—Å—Ö–æ–¥', '–ö—Ä–µ–¥–∏—Ç'] 
                       if c in df_analysis.columns), None)
        if amt_col:
            df_analysis['amount'] = df_analysis[amt_col].apply(clean_amt_val)
        else:
            df_analysis['amount'] = 0.0
    
    # Determine description
    desc_col = next((c for c in ['–î–µ—Ç–∞–ª–∏ –ø–ª–∞—Ç–µ–∂–∞', '–û–ø–∏—Å–∞–Ω–∏–µ –æ–ø–µ—Ä–∞—Ü–∏–∏', 'details', 
                                '–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ –ø–ª–∞—Ç–µ–∂–∞', 'operation'] if c in df_analysis.columns), None)
    df_analysis['details'] = df_analysis[desc_col].fillna('') if desc_col else ''
    
    # Determine counterparty
    import re
    def get_cp_data(row):
        cp_candidates = ['–ö–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç', '–ö–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç (–∏–º—è)', '–ö–æ—Ä—Ä–µ—Å–ø–æ–Ω–¥–µ–Ω—Ç', '–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –ø–æ–ª—É—á–∞—Ç–µ–ª—è']
        cp_text = ""
        for col in cp_candidates:
            if col in row and pd.notna(row[col]):
                cp_text = str(row[col])
                break
        
        bin_match = re.search(r'(\d{12})', cp_text)
        if bin_match:
            bin_val = bin_match.group(1)
            name = cp_text.split('–ë–ò–ù')[0].split('–ò–ò–ù')[0].split('\n')[0].strip()
            return bin_val, (name if name else bin_val)
        
        name_fallback = cp_text.split('\n')[0].strip() if cp_text else (row.get('details') or 'N/A')
        return str(name_fallback), str(name_fallback)
    
    cp_results = df_analysis.apply(get_cp_data, axis=1)
    df_analysis['counterparty_id'] = [x[0] for x in cp_results]
    df_analysis['counterparty_name'] = [x[1] for x in cp_results]
    
    # Generate analysis tables
    analysis = get_ui_analysis_tables(df_analysis)
    
    # Display tables
    col1, col2 = st.columns(2)
    with col1:
        st.write("**–†–∞—Å—Ö–æ–¥—ã (–î–µ–±–µ—Ç)**")
        if analysis["debit_top"]:
            st.dataframe(pd.DataFrame(analysis["debit_top"]), use_container_width=True, hide_index=True)
        else:
            st.info("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –ø–æ —Ä–∞—Å—Ö–æ–¥–∞–º")
    
    with col2:
        st.write("**–ü—Ä–∏—Ö–æ–¥—ã (–ö—Ä–µ–¥–∏—Ç)**")
        if analysis["credit_top"]:
            st.dataframe(pd.DataFrame(analysis["credit_top"]), use_container_width=True, hide_index=True)
        else:
            st.info("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –ø–æ –ø—Ä–∏—Ö–æ–¥–∞–º")
    
    st.subheader("–ê—Ñ—Ñ–∏–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ª–∏—Ü–∞ (Net —Ä–∞—Å—á–µ—Ç)")
    if analysis["related_parties"]:
        rp_df = pd.DataFrame(analysis["related_parties"])
        st.dataframe(rp_df.sort_values("–û–±–æ—Ä–æ—Ç", ascending=False), use_container_width=True, hide_index=True)
    else:
        st.info("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –ø–æ –∞—Ñ—Ñ–∏–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–º –ª–∏—Ü–∞–º")


def display_statement_source_tables(processed_results: List[Dict[str, Any]]) -> None:
    """
    Display only tx_ip table for each processed statement.
    """
    if not processed_results:
        return

    rows_with_statement = [r for r in processed_results if r.get("parsed_statement")]
    if not rows_with_statement:
        return

    st.header("üìë –¢–∞–±–ª–∏—Ü—ã –≤—ã–ø–∏—Å–∫–∏ (CSV-—ç–∫–≤–∏–≤–∞–ª–µ–Ω—Ç)")

    for idx, row in enumerate(rows_with_statement):
        stmnt = row.get("parsed_statement")
        if stmnt is None:
            continue

        pdf_name = getattr(stmnt, "pdf_name", row.get("statement_name", f"statement_{idx + 1}"))
        bank_name = format_bank_name(getattr(stmnt, "bank", "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"))
        tx_ip_df = getattr(stmnt, "enriched_df", None)

        with st.expander(f"{pdf_name} ({bank_name})", expanded=(idx == 0)):
            if tx_ip_df is not None and not tx_ip_df.empty:
                st.dataframe(tx_ip_df, use_container_width=True, hide_index=True)
            else:
                st.info("tx_ip: –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö")


def format_taxpayer_response(data: Dict[str, Any]) -> str:
    """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ API –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
    if not data:
        return "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö"
    
    responses = data.get("taxpayerPortalSearchResponses", [])
    if not responses:
        return "–ù–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"
    
    formatted = []
    for resp in responses:
        result = []
        result.append(f"**UID —Å–æ–æ–±—â–µ–Ω–∏—è:** {resp.get('responseMessageUid', 'N/A')}")
        result.append(f"**–†–µ–∑—É–ª—å—Ç–∞—Ç:** {resp.get('messageResult', 'N/A')}")
        result.append(f"**–ö–æ–¥:** {resp.get('code', 'N/A')}")
        result.append(f"**–¢–∏–ø:** {resp.get('taxpayerType', 'N/A')}")
        
        if resp.get('name'):
            result.append(f"**–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ:** {resp['name']}")
        
        if resp.get('fullName'):
            full_name = resp['fullName']
            name_parts = []
            if full_name.get('lastName'):
                name_parts.append(full_name['lastName'])
            if full_name.get('firstName'):
                name_parts.append(full_name['firstName'])
            if full_name.get('middleName'):
                name_parts.append(full_name['middleName'])
            if name_parts:
                result.append(f"**–§–ò–û:** {' '.join(name_parts)}")
        
        if resp.get('beginDate'):
            result.append(f"**–î–∞—Ç–∞ –Ω–∞—á–∞–ª–∞:** {resp['beginDate']}")
        
        if resp.get('endDate'):
            result.append(f"**–î–∞—Ç–∞ –æ–∫–æ–Ω—á–∞–Ω–∏—è:** {resp['endDate']}")
        
        if resp.get('endReason'):
            end_reason = resp['endReason']
            result.append(f"**–ü—Ä–∏—á–∏–Ω–∞ –æ–∫–æ–Ω—á–∞–Ω–∏—è:** {end_reason.get('ru', end_reason.get('code', 'N/A'))}")
        
        if resp.get('lzchpTypes'):
            result.append("**–¢–∏–ø—ã –õ–ó–ß–ü:**")
            for lzchp_type in resp['lzchpTypes']:
                result.append(f"  - {lzchp_type.get('lzchpType', 'N/A')} "
                             f"(—Å {lzchp_type.get('beginDate', 'N/A')} "
                             f"–ø–æ {lzchp_type.get('endDate', 'N/A') or '–Ω–∞—Å—Ç–æ—è—â–µ–µ –≤—Ä–µ–º—è'})")
        
        formatted.append("\n".join(result))
    
    return "\n\n---\n\n".join(formatted)


def display_taxpayer_search_tab():
    """–û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤–∫–ª–∞–¥–∫–∏ –ø–æ–∏—Å–∫–∞ –Ω–∞–ª–æ–≥–æ–ø–ª–∞—Ç–µ–ª—å—â–∏–∫–∞"""
    st.header("üîç –ü–æ–∏—Å–∫ –ù–∞–ª–æ–≥–æ–ø–ª–∞—Ç–µ–ª—å—â–∏–∫–∞")
    st.markdown("""
    **–ü–æ–∏—Å–∫ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –Ω–∞–ª–æ–≥–æ–ø–ª–∞—Ç–µ–ª—å—â–∏–∫–µ —á–µ—Ä–µ–∑ API —Å–µ—Ä–≤–∏—Å–∞ ¬´–ü–æ–∏—Å–∫ –ù–∞–ª–æ–≥–æ–ø–ª–∞—Ç–µ–ª—å—â–∏–∫–∞¬ª.**
    
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è —Å–ª–µ–¥—É—é—â–∏–µ —Ç–∏–ø—ã –Ω–∞–ª–æ–≥–æ–ø–ª–∞—Ç–µ–ª—å—â–∏–∫–æ–≤:
    - **–ò–ü** (–ò–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã–π –ø—Ä–µ–¥–ø—Ä–∏–Ω–∏–º–∞—Ç–µ–ª—å)
    - **–õ–ó–ß–ü** (–õ–∏—Ü–æ, –∑–∞–Ω–∏–º–∞—é—â–µ–µ—Å—è —á–∞—Å—Ç–Ω–æ–π –ø—Ä–∞–∫—Ç–∏–∫–æ–π)
    - **–Æ–õ** (–Æ—Ä–∏–¥–∏—á–µ—Å–∫–æ–µ –ª–∏—Ü–æ)
    """)
    
    # –§–æ—Ä–º–∞ –ø–æ–∏—Å–∫–∞
    with st.form("taxpayer_search_form"):
        portal_host = st.text_input(
            "Portal Host *",
            value=TAXPAYER_API_PORTAL_HOST,
            help="–ë–∞–∑–æ–≤—ã–π URL –ø–æ—Ä—Ç–∞–ª–∞ —Å–µ—Ä–≤–∏—Å–∞ –ø–æ–∏—Å–∫–∞"
        )
        portal_token = st.text_input(
            "X-Portal-Token *",
            value="",
            type="password",
            help="–£–∫–∞–∂–∏—Ç–µ —Ç–æ–∫–µ–Ω –≤—Ä—É—á–Ω—É—é –¥–ª—è —Ç–µ–∫—É—â–µ–π —Å–µ—Å—Å–∏–∏"
        )
        st.divider()
        col1, col2 = st.columns(2)
        
        with col1:
            taxpayer_type = st.selectbox(
                "–¢–∏–ø –Ω–∞–ª–æ–≥–æ–ø–ª–∞—Ç–µ–ª—å—â–∏–∫–∞ *",
                options=["IP", "LZCHP", "UL"],
                help="–í—ã–±–µ—Ä–∏—Ç–µ —Ç–∏–ø –Ω–∞–ª–æ–≥–æ–ø–ª–∞—Ç–µ–ª—å—â–∏–∫–∞"
            )
            
            taxpayer_code = st.text_input(
                "–ò–ò–ù/–ë–ò–ù *",
                placeholder="444444444444",
                help="12-–∑–Ω–∞—á–Ω—ã–π –ò–ò–ù –∏–ª–∏ –ë–ò–ù –Ω–∞–ª–æ–≥–æ–ø–ª–∞—Ç–µ–ª—å—â–∏–∫–∞",
                max_chars=12
            )
        
        with col2:
            if taxpayer_type == "LZCHP":
                first_name = st.text_input("–ò–º—è *", placeholder="First")
                last_name = st.text_input("–§–∞–º–∏–ª–∏—è *", placeholder="Last")
                name = None
            else:
                name = st.text_input("–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ *", placeholder="TOO")
                first_name = None
                last_name = None
        
        submitted = st.form_submit_button("üîç –ù–∞–π—Ç–∏", type="primary")
    
    if submitted:
        if not portal_host.strip():
            st.error("‚ùå –£–∫–∞–∂–∏—Ç–µ Portal Host")
            return
        if not portal_token.strip():
            st.error("‚ùå –£–∫–∞–∂–∏—Ç–µ X-Portal-Token")
            return
        if not taxpayer_code or len(taxpayer_code) != 12 or not taxpayer_code.isdigit():
            st.error("‚ùå –ò–ò–ù/–ë–ò–ù –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å—Ç—Ä–æ–∫–æ–π –∏–∑ 12 —Ü–∏—Ñ—Ä")
            return
        
        if taxpayer_type == "LZCHP":
            if not first_name or not last_name:
                st.error("‚ùå –î–ª—è –õ–ó–ß–ü –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ —É–∫–∞–∑–∞—Ç—å –∏–º—è –∏ —Ñ–∞–º–∏–ª–∏—é")
                return
        else:
            if not name:
                st.error("‚ùå –î–ª—è –ò–ü –∏ –Æ–õ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ —É–∫–∞–∑–∞—Ç—å –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ")
                return
        
        with st.spinner("üîç –í—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –ø–æ–∏—Å–∫..."):
            try:
                client = TaxpayerAPIClient(
                    portal_host=portal_host.strip(),
                    portal_token=portal_token.strip()
                )
                
                taxpayer_type_enum = TaxpayerType[taxpayer_type]
                result = client.search_taxpayer(
                    taxpayer_code=taxpayer_code,
                    taxpayer_type=taxpayer_type_enum,
                    name=name,
                    first_name=first_name,
                    last_name=last_name,
                    print=False
                )
                
                search_record = {
                    "taxpayer_code": taxpayer_code,
                    "taxpayer_type": taxpayer_type,
                    "result": result,
                }
                st.session_state.taxpayer_search_results.insert(0, search_record)
                
                st.success("‚úÖ –ü–æ–∏—Å–∫ –≤—ã–ø–æ–ª–Ω–µ–Ω!")
                
                if result.get("success"):
                    st.subheader("üìä –†–µ–∑—É–ª—å—Ç–∞—Ç –ø–æ–∏—Å–∫–∞")
                    data = result.get("data", {})
                    with st.expander("üìã JSON –æ—Ç–≤–µ—Ç", expanded=True):
                        st.json(data)
                    formatted = format_taxpayer_response(data)
                    if formatted:
                        st.markdown("### üìù –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç")
                        st.markdown(formatted)
                else:
                    st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞: {result.get('error', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞')}")
                    if result.get("message"):
                        st.error(f"–î–µ—Ç–∞–ª–∏: {result['message']}")
            
            except Exception as e:
                st.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {str(e)}")
                st.exception(e)
    
    # –ò—Å—Ç–æ—Ä–∏—è –ø–æ–∏—Å–∫–æ–≤
    if st.session_state.taxpayer_search_results:
        st.divider()
        st.header("üìú –ò—Å—Ç–æ—Ä–∏—è –ø–æ–∏—Å–∫–æ–≤")
        for idx, record in enumerate(st.session_state.taxpayer_search_results[:5]):
            with st.expander(f"üîç {record['taxpayer_type']} - {record['taxpayer_code']}"):
                result = record["result"]
                if result.get("success"):
                    data = result.get("data", {})
                    st.json(data)
                else:
                    st.error(f"–û—à–∏–±–∫–∞: {result.get('error', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞')}")


def main() -> None:
    """Main application"""
    st.set_page_config(
        page_title="–ó–∞–≥—Ä—É–∑–∫–∞ –±–∞–Ω–∫–æ–≤—Å–∫–∏—Ö –≤—ã–ø–∏—Å–æ–∫",
        page_icon="üìÑ",
        layout="wide"
    )
    
    init_session_state()
    
    # –í–∫–ª–∞–¥–∫–∏ –¥–ª—è –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏—è –º–µ–∂–¥—É —Ñ—É–Ω–∫—Ü–∏—è–º–∏
    tab1, tab2 = st.tabs(["üìÑ –ó–∞–≥—Ä—É–∑–∫–∞ –≤—ã–ø–∏—Å–æ–∫", "üîç –ü–æ–∏—Å–∫ –Ω–∞–ª–æ–≥–æ–ø–ª–∞—Ç–µ–ª—å—â–∏–∫–∞"])
    
    with tab1:
        st.title("üìÑ –ó–∞–≥—Ä—É–∑–∫–∞ –±–∞–Ω–∫–æ–≤—Å–∫–∏—Ö –≤—ã–ø–∏—Å–æ–∫")
        st.markdown("""
        **–ó–∞–≥—Ä—É–∑–∏—Ç–µ –æ–¥–Ω—É –∏–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ –≤—ã–ø–∏—Å–æ–∫. –°–∏—Å—Ç–µ–º–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏:**
        - üîç –û–ø—Ä–µ–¥–µ–ª–∏—Ç –±–∞–Ω–∫ –¥–ª—è –∫–∞–∂–¥–æ–π –≤—ã–ø–∏—Å–∫–∏
        - üÜî –ò–∑–≤–ª–µ—á–µ—Ç –ò–ò–ù –∏–∑ –≤—ã–ø–∏—Å–∫–∏
        - üìÅ –°–≥—Ä—É–ø–ø–∏—Ä—É–µ—Ç –≤—ã–ø–∏—Å–∫–∏ –ø–æ –ò–ò–ù
        - üíæ –°–æ—Ö—Ä–∞–Ω–∏—Ç –≤—Å–µ –¥–∞–Ω–Ω—ã–µ –≤ –ë–î
        - üí∞ –†–∞—Å—Å—á–∏—Ç–∞–µ—Ç –¥–æ—Ö–æ–¥ –∑–∞ 12 –º–µ—Å—è—Ü–µ–≤
        """)
        
        # Ensure schema for project workflow
        try:
            _ensure_project_schema()
        except Exception as e:
            st.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Å—Ö–µ–º—É –ø—Ä–æ–µ–∫—Ç–æ–≤: {e}")
            return

        # Date selection for testing
        with st.sidebar:
            st.header("‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏")
            api_ok, api_msg = check_api_health()
            if api_ok:
                st.success(f"üîå API: {api_msg}")
            else:
                st.warning(f"üîå API: {api_msg}")
            st.caption(f"API_BASE_URL: {API_BASE_URL}")
            st.session_state.anchor_date = st.date_input(
                "üìÖ –î–∞—Ç–∞ –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ (—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ)",
                value=st.session_state.anchor_date,
                help="–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ 12-–º–µ—Å—è—á–Ω–æ–≥–æ –æ–∫–Ω–∞ –¥–æ—Ö–æ–¥–∞"
            )
            
            # Show calculated window (–≥–æ–¥ –Ω–∞—á–∏–Ω–∞—è —Å –≤—ã–±—Ä–∞–Ω–Ω–æ–π –¥–∞—Ç—ã)
            window_start, window_end = get_last_full_12m_window(st.session_state.anchor_date)
            st.info(f"**–û–∫–Ω–æ –∞–Ω–∞–ª–∏–∑–∞ (–ø–æ—Å–ª–µ–¥–Ω–∏–µ 12 –ø–æ–ª–Ω—ã—Ö –º–µ—Å—è—Ü–µ–≤):**\n{window_start} ‚Üí {window_end}")
            
            if st.button("üîÑ –°–±—Ä–æ—Å–∏—Ç—å –Ω–∞ —Å–µ–≥–æ–¥–Ω—è"):
                st.session_state.anchor_date = date.today()
                st.rerun()

        st.header("0. –ü—Ä–æ–µ–∫—Ç")
        project_col1, project_col2 = st.columns([2, 1])
        with project_col1:
            projects = _list_projects()
            project_options = [None] + [str(p["id"]) for p in projects]
            project_label_map = {None: "–í—ã–±–µ—Ä–∏—Ç–µ –ø—Ä–æ–µ–∫—Ç"}
            for p in projects:
                project_label_map[str(p["id"])] = f'{p["name"]} ({p["statements_count"]}/9, {p["status"]})'

            st.session_state.selected_project_id = st.selectbox(
                "–¢–µ–∫—É—â–∏–π –ø—Ä–æ–µ–∫—Ç",
                options=project_options,
                index=project_options.index(st.session_state.selected_project_id)
                if st.session_state.selected_project_id in project_options else 0,
                format_func=lambda x: project_label_map.get(x, str(x)),
                help="–°–Ω–∞—á–∞–ª–∞ —Å–æ–∑–¥–∞–π—Ç–µ –∏–ª–∏ –≤—ã–±–µ—Ä–∏—Ç–µ –ø—Ä–æ–µ–∫—Ç",
            )
        with project_col2:
            new_project_name = st.text_input("–ù–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞", value="")
            if st.button("‚ûï –°–æ–∑–¥–∞—Ç—å –ø—Ä–æ–µ–∫—Ç", type="secondary"):
                if not new_project_name.strip():
                    st.warning("–í–≤–µ–¥–∏—Ç–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞")
                else:
                    pid = _create_project(new_project_name.strip())
                    st.session_state.selected_project_id = pid
                    st.success(f"–ü—Ä–æ–µ–∫—Ç —Å–æ–∑–¥–∞–Ω: {pid}")
                    st.rerun()
    
        # File upload section
        st.header("1. –ó–∞–≥—Ä—É–∑–∫–∞ –≤—ã–ø–∏—Å–æ–∫")
        uploaded_files = st.file_uploader(
            "–í—ã–±–µ—Ä–∏—Ç–µ —Ñ–∞–π–ª—ã –≤—ã–ø–∏—Å–æ–∫ (PDF)",
            type=["pdf"],
            accept_multiple_files=True,
            help="–ú–æ–∂–Ω–æ –∑–∞–≥—Ä—É–∑–∏—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –≤—ã–ø–∏—Å–æ–∫ —Ä–∞–∑–Ω—ã—Ö –±–∞–Ω–∫–æ–≤ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ"
        )
        
        processor = StatementProcessor()
        
        selected_project_id = st.session_state.selected_project_id
        if uploaded_files and st.button(
            "üöÄ –û–±—Ä–∞–±–æ—Ç–∞—Ç—å –∏ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ –ø—Ä–æ–µ–∫—Ç",
            type="primary",
            disabled=not bool(selected_project_id)
        ):
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            status_text.text(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ {len(uploaded_files)} –≤—ã–ø–∏—Å–æ–∫...")
            progress_bar.progress(0.1)
            
            # Process statements and attach to selected project
            try:
                if not selected_project_id:
                    raise ValueError("–°–Ω–∞—á–∞–ª–∞ –≤—ã–±–µ—Ä–∏—Ç–µ –ø—Ä–æ–µ–∫—Ç")

                existing_count = _count_project_statements(selected_project_id)
                if existing_count + len(uploaded_files) > 9:
                    raise ValueError(f"–í –ø—Ä–æ–µ–∫—Ç–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –º–∞–∫—Å–∏–º—É–º 9 –≤—ã–ø–∏—Å–æ–∫. –£–∂–µ –∑–∞–≥—Ä—É–∂–µ–Ω–æ: {existing_count}")

                result_data = process_statements_for_project(
                    uploaded_files,
                    project_id=selected_project_id,
                    processor=processor,
                    anchor_date=st.session_state.anchor_date
                )
                
                progress_bar.progress(1.0)
                progress_bar.empty()
                status_text.empty()
                
                # Store results
                st.session_state.upload_results = result_data["results"]
                st.session_state.processed_statements = [
                    r for r in result_data["results"]
                    if r.get("parsed_statement") and r.get("status") == "success"
                ]
                st.session_state.projects_created = []

                st.success(
                    f"‚úÖ –ü—Ä–æ–µ–∫—Ç {selected_project_id}: "
                    f"—É—Å–ø–µ—à–Ω–æ {result_data['processed']}, "
                    f"–ø—Ä–æ–ø—É—â–µ–Ω–æ {result_data['skipped']}, "
                    f"–æ—à–∏–±–æ–∫ {result_data['failed']}"
                )
                st.rerun()
                
            except Exception as e:
                progress_bar.empty()
                status_text.empty()
                st.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ: {str(e)}")
                st.exception(e)
        
        # Display projects created
        if st.session_state.projects_created:
            st.header("üìÅ –°–æ–∑–¥–∞–Ω–Ω—ã–µ –ø—Ä–æ–µ–∫—Ç—ã")
        projects_data = []
        for p in st.session_state.projects_created:
            projects_data.append({
                "ID –ø—Ä–æ–µ–∫—Ç–∞": p["project_id"],
                "–ò–ò–ù": p["iin"],
                "–°—Ç–∞—Ç—É—Å": "–£—Å–ø–µ—Ö" if p["status"] == 0 else ("–ü—Ä–æ–≤–∞–ª" if p["status"] == 1 else "–†–∞—Å—Ö–æ–∂–¥–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö"),
                "–°–æ–æ–±—â–µ–Ω–∏–µ": p["message"],
                "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤—ã–ø–∏—Å–æ–∫": p["statements_count"],
                "–î–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è": p["create_date"].strftime("%d.%m.%Y %H:%M:%S") if isinstance(p["create_date"], datetime) else str(p["create_date"]),
            })
        
        if projects_data:
            df_projects = pd.DataFrame(projects_data)
            st.dataframe(df_projects, use_container_width=True, hide_index=True)
            
            # Show analytics for each project
            for p in st.session_state.projects_created:
                if p.get("analytics"):
                    with st.expander(f"üìä –ê–Ω–∞–ª–∏—Ç–∏–∫–∞ –ø—Ä–æ–µ–∫—Ç–∞ {p['project_id']} (–ò–ò–ù: {p['iin']})"):
                        analytics = p["analytics"]
                        if analytics.get("iin"):
                            st.write(f"**–ò–ò–ù:** {analytics['iin']}")
                        if analytics.get("registration_date"):
                            st.write(f"**–î–∞—Ç–∞ —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏:** {analytics['registration_date']}")
                        if analytics.get("average_income"):
                            st.write(f"**–°—Ä–µ–¥–Ω–∏–π –¥–æ—Ö–æ–¥:** {analytics['average_income']:,.2f} ‚Ç∏")
    
        # Display results if available
        if st.session_state.upload_results:
            display_results(st.session_state.upload_results)
            display_statement_source_tables(st.session_state.upload_results)
            
            # Display admin tables
            if st.session_state.processed_statements:
                st.divider()
                display_admin_tables(st.session_state.processed_statements)
        
        # Clear results button
        if st.session_state.upload_results:
            if st.button("üóëÔ∏è –û—á–∏—Å—Ç–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã"):
                st.session_state.upload_results = []
                st.session_state.processed_statements = []
                st.session_state.projects_created = []
                st.rerun()
        
        # Database management section
        st.divider()
        with st.expander("üóÑÔ∏è –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –±–∞–∑–æ–π –¥–∞–Ω–Ω—ã—Ö", expanded=False):
            st.warning("‚ö†Ô∏è –û–ø–∞—Å–Ω–∞—è –∑–æ–Ω–∞: –æ–ø–µ—Ä–∞—Ü–∏–∏ —Å –±–∞–∑–æ–π –¥–∞–Ω–Ω—ã—Ö")
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.subheader("–û—á–∏—Å—Ç–∫–∞ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö")
                st.write("–£–¥–∞–ª—è–µ—Ç –≤—Å–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ –≤—Å–µ—Ö —Ç–∞–±–ª–∏—Ü. –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ë–î —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è.")
                
                confirm_text = st.text_input(
                    "–í–≤–µ–¥–∏—Ç–µ '–û–ß–ò–°–¢–ò–¢–¨' –¥–ª—è –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è:",
                    key="clear_db_confirm",
                    help="–≠—Ç–æ –¥–µ–π—Å—Ç–≤–∏–µ –Ω–µ–æ–±—Ä–∞—Ç–∏–º–æ!"
                )
                
                if st.button("üóëÔ∏è –û—á–∏—Å—Ç–∏—Ç—å –ë–î", type="secondary", disabled=confirm_text != "–û–ß–ò–°–¢–ò–¢–¨"):
                    try:
                        db = DatabaseConnection(**DB_CONFIG)
                        db.connect()
                        cursor = db.connection.cursor()
                        
                        # –û—Ç–∫–ª—é—á–∏—Ç—å –ø—Ä–æ–≤–µ—Ä–∫—É –≤–Ω–µ—à–Ω–∏—Ö –∫–ª—é—á–µ–π
                        cursor.execute("SET session_replication_role = 'replica';")
                        
                        # –û—á–∏—Å—Ç–∏—Ç—å —Ç–∞–±–ª–∏—Ü—ã
                        tables = [
                            'transactions_ip_flags',
                            'transactions',
                            'ip_income_monthly',
                            'income_summaries',
                            'statement_metadata',
                            'statement_footers',
                            'statement_headers',
                            'counterparties',
                            'statements',
                            'accounts',
                            'clients'
                        ]
                        
                        cleared = []
                        for table in tables:
                            try:
                                db.safe_truncate_table(table)
                                cleared.append(table)
                            except Exception as e:
                                st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—á–∏—Å—Ç–∫–µ {table}: {e}")
                        
                        # –í–∫–ª—é—á–∏—Ç—å –æ–±—Ä–∞—Ç–Ω–æ –ø—Ä–æ–≤–µ—Ä–∫—É –≤–Ω–µ—à–Ω–∏—Ö –∫–ª—é—á–µ–π
                        cursor.execute("SET session_replication_role = 'origin';")
                        db.connection.commit()
                        
                        # –ü—Ä–æ–≤–µ—Ä–∫–∞
                        counts = {}
                        table_names_ru = {
                            'clients': '–ö–ª–∏–µ–Ω—Ç—ã',
                            'accounts': '–°—á–µ—Ç–∞',
                            'statements': '–í—ã–ø–∏—Å–∫–∏',
                            'transactions': '–¢—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏'
                        }
                        for table in ['clients', 'accounts', 'statements', 'transactions']:
                            counts[table_names_ru[table]] = db.safe_count_table(table)
                        
                        cursor.close()
                        db.disconnect()
                        
                        st.success(f"‚úÖ –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –æ—á–∏—â–µ–Ω–∞! –û—á–∏—â–µ–Ω–æ —Ç–∞–±–ª–∏—Ü: {len(cleared)}")
                        st.json(counts)
                        st.rerun()
                        
                    except Exception as e:
                        st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—á–∏—Å—Ç–∫–µ –ë–î: {e}")
                        st.exception(e)
            
            with col2:
                st.subheader("–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö")
                
                if st.button("üìä –û–±–Ω–æ–≤–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É"):
                    try:
                        db = DatabaseConnection(**DB_CONFIG)
                        db.connect()
                        
                        stats = {}
                        tables = ['clients', 'accounts', 'statements', 'transactions', 'income_summaries']
                        table_names_ru = {
                            'clients': '–ö–ª–∏–µ–Ω—Ç—ã',
                            'accounts': '–°—á–µ—Ç–∞',
                            'statements': '–í—ã–ø–∏—Å–∫–∏',
                            'transactions': '–¢—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏',
                            'income_summaries': '–†–∞—Å—á–µ—Ç—ã –¥–æ—Ö–æ–¥–∞'
                        }
                        
                        for table in tables:
                            try:
                                stats[table_names_ru[table]] = db.safe_count_table(table)
                            except Exception:
                                stats[table_names_ru[table]] = "–ù/–î"
                        
                        db.disconnect()
                        
                        st.json(stats)
                        
                        # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ –≤–∏–¥–µ –º–µ—Ç—Ä–∏–∫
                        col_a, col_b, col_c = st.columns(3)
                        with col_a:
                            st.metric("–ö–ª–∏–µ–Ω—Ç—ã", stats.get('–ö–ª–∏–µ–Ω—Ç—ã', 0))
                        with col_b:
                            st.metric("–°—á–µ—Ç–∞", stats.get('–°—á–µ—Ç–∞', 0))
                        with col_c:
                            st.metric("–í—ã–ø–∏—Å–∫–∏", stats.get('–í—ã–ø–∏—Å–∫–∏', 0))
                    
                    except Exception as e:
                        st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {e}")
    
    with tab2:
        display_taxpayer_search_tab()


if __name__ == "__main__":
    main()
